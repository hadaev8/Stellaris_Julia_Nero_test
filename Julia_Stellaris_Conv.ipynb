{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0. Load train images\n",
    "#1. Genetic Algorithm work\n",
    "#2. Make convolutional network for images\n",
    "#3. Evaluation of the generated images and sort\n",
    "#4. Make Stellaris file from all images\n",
    "#5. ...\n",
    "#6. PROFIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "# not worked without it\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# python helpers\n",
    "from __future__ import division, print_function, absolute_import\n",
    "import pickle\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from time import time\n",
    "# genetic lib\n",
    "from pygene3.gene import IntGeneRandom, DiscreteGene\n",
    "from pygene3.organism import Organism\n",
    "from pygene3.population import Population\n",
    "# nero lib\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "# dirs\n",
    "desktop = os.path.join(os.environ['USERPROFILE'], 'Desktop')\n",
    "work_dir = os.path.join(desktop, 'Stellaris_Julia_Nero_test')\n",
    "\n",
    "good_pics_dir = os.path.join(work_dir, 'good_pics')\n",
    "bad_pics_dir = os.path.join(work_dir, 'bad_pics')\n",
    "good_pics_sorted_dir = os.path.join(work_dir, 'good_pics_sorted')\n",
    "bad_pics_sorted_dir = os.path.join(work_dir, 'bad_pics_sorted')\n",
    "unsorted_pics_dir = os.path.join(work_dir, 'unsorted_pics')\n",
    "stellaris_maps_dir = os.path.join(work_dir, 'map\\\\setup_scenarios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#0. Load train images\n",
    "\n",
    "good_pics = np.array(glob.glob(good_pics_dir + '\\\\*.jpg'))\n",
    "x = np.array([np.array(Image.open(fname)) for fname in good_pics])\n",
    "x = x[:,:,:,[3]]\n",
    "y = np.ones(x.shape[0])\n",
    "\n",
    "bad_pics = np.array(glob.glob(bad_pics_dir + '\\\\*.jpg'))\n",
    "xtest = np.array([np.array(Image.open(fname)) for fname in bad_pics])\n",
    "\n",
    "xtest = xtest[:,:,:,[3]]\n",
    "ytest = np.zeros(xtest.shape[0])\n",
    "\n",
    "xtest, ytest = shuffle(xtest, ytest)\n",
    "\n",
    "# take part of bad for train\n",
    "x1 = xtest[0:x.shape[0]]\n",
    "y1 = ytest[0:x.shape[0]]\n",
    "\n",
    "y = np.concatenate((y, y1))\n",
    "x = np.concatenate((x, x1))\n",
    "ytest = np.concatenate((y, ytest))\n",
    "xtest = np.concatenate((x, xtest))\n",
    "\n",
    "xtest, ytest = shuffle(xtest, ytest)\n",
    "x, y = shuffle(x, y)\n",
    "\n",
    "y = to_categorical(y, 2)\n",
    "ytest = to_categorical(ytest, 2)\n",
    "\n",
    "# save by pikle for fater load in future\n",
    "with open(os.path.join(work_dir, 'julia.pickle'), 'wb') as handle:\n",
    "    pickle.dump([x, y, xtest, ytest], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. Genetic Algorithm work\n",
    "# GA classes\n",
    "class ConvGene(IntGeneRandom):\n",
    "    mutProb = 0.3\n",
    "    mutAmt = 1\n",
    "    randMin = 1\n",
    "    randMax = 5\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.value)\n",
    "    \n",
    "class FilterGene(IntGeneRandom):\n",
    "    mutProb = 0.3\n",
    "    mutAmt = 1\n",
    "    randMin = 2\n",
    "    randMax = 16\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.value)\n",
    "    \n",
    "class NeuronGene(IntGeneRandom):\n",
    "    mutProb = 0.3\n",
    "    mutAmt = 20\n",
    "    randMin = 300\n",
    "    randMax = 500\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.value)\n",
    "\n",
    "class Julia_Network:\n",
    "    def __init__(self, conv1, conv2, conv3, filter1, filter2, filter3, neronum):\n",
    "        self.conv1 = conv1\n",
    "        self.conv2 = conv2\n",
    "        self.conv3 = conv3\n",
    "        self.filter1 = filter1\n",
    "        self.filter2 = filter2\n",
    "        self.filter3 = filter3\n",
    "        self.neronum = neronum\n",
    "        \n",
    "        network = input_data(shape=[None, 100, 100, 1])\n",
    "        if self.conv1 > 1:\n",
    "            network = conv_2d(network, self.filter1, self.conv1, activation='relu')\n",
    "            network = max_pool_2d(network, 2)\n",
    "        if self.conv2 > 1:\n",
    "            network = conv_2d(network, self.filter2, self.conv2, activation='relu')\n",
    "            network = max_pool_2d(network, 2)\n",
    "        if self.conv3 > 1:\n",
    "            network = conv_2d(network, self.filter3, self.conv3, activation='relu')\n",
    "            network = max_pool_2d(network, 2)\n",
    "        network = fully_connected(network, self.neronum, activation='relu')\n",
    "        network = dropout(network, 0.8)\n",
    "        network = fully_connected(network, y.shape[1], activation='softmax')\n",
    "        network = regression(network, optimizer='adam',\n",
    "                             loss='categorical_crossentropy',\n",
    "                             learning_rate=0.001,\n",
    "                            )\n",
    "        self.model = tflearn.DNN(network, tensorboard_verbose=0,\n",
    "                                #checkpoint_path='julia_classifier.tfl.ckpt',\n",
    "                                max_checkpoints = 0,\n",
    "                               )\n",
    "\n",
    "class Julia_Solver(Organism):\n",
    "    \n",
    "    genome = {\n",
    "        'conv1' : ConvGene,\n",
    "        'conv2' : ConvGene,\n",
    "        'conv3' : ConvGene,\n",
    "        'filter1' : FilterGene,\n",
    "        'filter2' : FilterGene,\n",
    "        'filter3' : FilterGene,\n",
    "        'neronum' : NeuronGene,\n",
    "    }\n",
    "    \n",
    "    def fitness(self):\n",
    "        # not worked without it\n",
    "        tf.reset_default_graph()\n",
    "        currentnetwork = Julia_Network(self['conv1'], self['conv2'], self['conv3'], self['filter1'], self['filter2'], self['filter3'], self['neronum'])\n",
    "        currentnetwork.model.fit(x, y, n_epoch=30,#self['n_epoch'],\n",
    "                                shuffle=True,\n",
    "                                show_metric=False,\n",
    "                                snapshot_epoch=False,\n",
    "                                #batch_size=98,\n",
    "                                #validation_set=0.5\n",
    "                            )\n",
    "        \n",
    "        result = currentnetwork.model.evaluate(xtest, ytest)\n",
    "        #del currentnetwork\n",
    "        return (-1*result[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<fitness=%f conv1=%s conv2=%s conv3=%s filter1=%s filter2=%s filter3=%s neronum=%s>' % (\n",
    "            self.fitness(), self['conv1'], self['conv2'], self['conv3'], self['filter1'], self['filter2'], self['filter3'], self['neronum'])\n",
    "    \n",
    "class Julia_Population(Population):\n",
    "    species = Julia_Solver\n",
    "    initPopulation = 30\n",
    "    # max pops\n",
    "    childCull = 15\n",
    "    # reproduse pops\n",
    "    childCount = 30\n",
    "    mutants = 1#0.8\n",
    "    mutateAfterMating = True\n",
    "    numNewOrganisms = 0\n",
    "    # we need best net\n",
    "    incest = 1\n",
    "    \n",
    "# GA work\n",
    "with open(os.path.join(work_dir, 'julia.pickle'), 'rb') as handle:\n",
    "    x, y, xtest, ytest = pickle.load(handle)\n",
    "    \n",
    "# create population\n",
    "ph = Julia_Population()\n",
    "\n",
    "timer = time()\n",
    "\n",
    "print('gogo')\n",
    "# 20 generations\n",
    "i = 0\n",
    "while True:\n",
    "    b = ph.best()\n",
    "    # statistics\n",
    "    current_time = (time() - timer)/60\n",
    "    stat = 'generation %02d: %s average=%s time=%.1f min)' % (\n",
    "        i, repr(b), ph.fitness(), current_time)\n",
    "    \n",
    "    print(stat)\n",
    "    # stats to file\n",
    "    with open(os.path.join(work_dir, 'log.txt'), 'a') as handle:\n",
    "        handle.write(stat)\n",
    "        handle.write('\\n')\n",
    "\n",
    "    if b.get_fitness() < -0.99:\n",
    "        break\n",
    "        \n",
    "    if i > 20:\n",
    "        break\n",
    "\n",
    "    #sys.stdout.flush()\n",
    "    i += 1\n",
    "    ph.gen()\n",
    "print(repr(b))\n",
    "# sleep mod\n",
    "os.system(r'rundll32.exe powrprof.dll,SetSuspendState Hibernate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5670  | total loss: \u001b[1m\u001b[32m0.02305\u001b[0m\u001b[0m | time: 6.024s\n",
      "| Adam | epoch: 030 | loss: 0.02305 - acc: 0.9909 -- iter: 12040/12040\n",
      "INFO:tensorflow:C:\\Users\\Andrey\\Desktop\\Stellaris_Julia_Nero_test\\julia_classifier.tfl is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Network trained and saved as julia_classifier.tfl\n",
      "[0.9697405599794503]\n",
      "3.4897496064503986\n"
     ]
    }
   ],
   "source": [
    "#2. Make convolutional network for images\n",
    "with open(os.path.join(work_dir, 'julia.pickle'), 'rb') as handle:\n",
    "    x, y, xtest, ytest = pickle.load(handle)\n",
    "\n",
    "timer = time()\n",
    "# not worked without this\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# network \n",
    "network = input_data(shape=[None, 100, 100, 1])\n",
    "network = conv_2d(network, 3, 11, activation='relu')\n",
    "network = max_pool_2d(network, 2)\n",
    "\n",
    "network = conv_2d(network, 3, 10, activation='relu')\n",
    "network = max_pool_2d(network, 2)\n",
    "\n",
    "network = conv_2d(network, 2, 11, activation='relu')\n",
    "network = max_pool_2d(network, 2)\n",
    "\n",
    "network = fully_connected(network, 309, activation='relu')\n",
    "network = dropout(network, 0.8)\n",
    "\n",
    "network = fully_connected(network, y.shape[1], activation='softmax')\n",
    "network = regression(network, optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.001,\n",
    "                    )\n",
    "\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0,\n",
    "                    checkpoint_path='julia_classifier.tfl.ckpt',\n",
    "                    #best_checkpoint_path='superclassifier_best.tfl.ckpt',   \n",
    "                    max_checkpoints = 0,\n",
    "                   )\n",
    "\n",
    "model.fit(x, y, n_epoch=30, shuffle=True,\n",
    "          show_metric=True,\n",
    "          #batch_size=30,\n",
    "          snapshot_epoch=False,\n",
    "          #snapshot_step = 30,\n",
    "          #validation_set=0.3,\n",
    "          run_id='julia_classifier'\n",
    "         )\n",
    "model.save(os.path.join(work_dir, 'julia_classifier.tfl'))\n",
    "# can load model if needed\n",
    "#model.load(os.path.join(work_dir, 'julia_classifier.tfl'))\n",
    "print('Network trained and saved as julia_classifier.tfl')\n",
    "print(model.evaluate(xtest, ytest))\n",
    "print((time() - timer)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#3. Evaluation of the generated images and sort\n",
    "unsorted_pics = np.array(glob.glob(unsorted_pics_dir + '\\\\*.jpg'))\n",
    "xsort = np.array([np.array(Image.open(fname)) for fname in unsorted_pics])\n",
    "xsort = xsort[:,:,:,[3]]\n",
    "\n",
    "for i, pic in enumerate(xsort):\n",
    "    result = model.predict_label(xsort[i:i+1])\n",
    "    name = str(i) + '.jpg'\n",
    "    #name = os.path.split(unsorted_pics[i])[1]\n",
    "    if result[0][0] == 1:\n",
    "        # move to good\n",
    "        os.rename(unsorted_pics[i], os.path.join(good_pics_sorted_dir, name))\n",
    "    else:\n",
    "        os.rename(unsorted_pics[i], os.path.join(bad_pics_sorted_dir, name))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Make Stellaris file from all images\n",
    "def gen_galaxy(current_pic):\n",
    "    pic = np.array(Image.open(current_pic))\n",
    "    s = 0\n",
    "    i = 0\n",
    "    coordinates = list()\n",
    "    while i < 100:\n",
    "        j = 0\n",
    "        while j < 100:\n",
    "            if pic[i][j][3] == 255:\n",
    "                s += 1\n",
    "                coordinates.append((i, j))\n",
    "                #print(i,j)\n",
    "            j += 1\n",
    "        i += 1\n",
    "    coordinates = shuffle(coordinates)\n",
    "    fname = os.path.splitext(os.path.basename(current_pic))[0]\n",
    "    #print(fname)\n",
    "    with open(os.path.join(stellaris_maps_dir, fname + '.txt'), 'w') as handle:\n",
    "        handle.write('#stars ' + str(s))\n",
    "        handle.write('\\nstatic_galaxy_scenario = {\\n\\tname = \\\"' + fname + '\\\"\\n\\tpriority = 0\\n\\tdefault = no\\n\\tcolonizable_planet_odds = 1.0\\n\\tnum_empires = { min = 0 max = 60 }\\n\\tnum_empire_default = 21\\n\\tfallen_empire_default = 4\\n\\tfallen_empire_max = 4\\n\\tadvanced_empire_default = 7\\n\\tcore_radius = 0\\n\\trandom_hyperlanes = yes\\n\\n')\n",
    "        for i, coordinate in enumerate(coordinates[0]):\n",
    "            y = (10 * (coordinate[0] - 50) + random.randint(-3, 4))\n",
    "            x = (10 * (coordinate[1] - 50) + random.randint(-4, 5))\n",
    "            # move away from border\n",
    "            if x > 500:\n",
    "                x -= 8\n",
    "            elif x < -500:\n",
    "                x += 8\n",
    "            if y > 500:\n",
    "                y -= 8\n",
    "            elif y < -500:\n",
    "                y += 8;\n",
    "            # write to file\n",
    "            handle.write('\\tsystem = {\\n\\t\\tid = ' + str(i) + '\\n\\t\\tposition = {\\n\\t\\t\\tx = ' + str(x) + '\\n\\t\\t\\ty = ' + str(y) + '\\n\\t\\t}\\n\\t}\\r')\n",
    "            # place some nebulas\n",
    "            if random.randint(0, 250) == 1:\n",
    "                handle.write('\\tnebula = {\\n\\t\\tposition = {\\n\\t\\t\\tx = ' + str(x) + '\\n\\t\\t\\ty = ' + str(y) + '\\n\\t\\t}\\n\\t\\tradius = ' + str(random.randint(40, 100)) + '\\n\\t}\\r')\n",
    "        handle.write('}')\n",
    "    return\n",
    "\n",
    "# make files for stellaris\n",
    "good_pics = np.array(glob.glob(good_pics_dir + '\\\\*.jpg'))\n",
    "for good_pic in good_pics:\n",
    "    gen_galaxy(good_pic)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. PROFIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# rename images\n",
    "good_pics = np.array(glob.glob(good_pics_dir + '\\\\*.jpg'))\n",
    "for i, pic in enumerate(good_pics):\n",
    "    #Insane Julia Set Nero Classification\n",
    "    name = 'IJSNC ' + str(i) + '.jpg'\n",
    "    os.rename(good_pics[i], os.path.join(good_pics_dir, name))\n",
    "bad_pics = np.array(glob.glob(bad_pics_dir + '\\\\*.jpg'))\n",
    "for i, pic in enumerate(bad_pics):\n",
    "    #Insane Julia Set Nero Classification\n",
    "    name = 'IJSNC_bad ' + str(i) + '.jpg'\n",
    "    os.rename(bad_pics[i], os.path.join(bad_pics_dir, name))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
